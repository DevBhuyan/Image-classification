{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sign Language - MultiClass Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPhPLF5MfIuXcXIRa3oQVuB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevBhuyan/Image-classification/blob/master/Sign_Language_MultiClass_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5q4MUot7r4a"
      },
      "source": [
        "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
        "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
        "# ATTENTION: Please use the provided epoch values when training.\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from os import getcwd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_inrXgmf8au0",
        "outputId": "def30d47-7d43-4abc-8022-990cd67ae0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "def get_data(filename):\n",
        "  # You will need to write code that will read the file passed\n",
        "  # into this function. The first line contains the column headers\n",
        "  # so you should ignore it\n",
        "  # Each successive line contians 785 comma separated values between 0 and 255\n",
        "  # The first value is the labels\n",
        "  # The rest are the pixel values for that picture\n",
        "  # The function will return 2 np.array types. One with all the labels\n",
        "  # One with all the images\n",
        "  #\n",
        "  # Tips: \n",
        "  # If you read a full line (as 'row') then row[0] has the label\n",
        "  # and row[1:785] has the 784 pixel values\n",
        "  # Take a look at np.array_split to turn the 784 pixels into 28x28\n",
        "  # You are reading in strings, but need the values to be floats\n",
        "  # Check out np.array().astype for a conversion\n",
        "    with open(filename) as training_file:\n",
        "      # Your code starts here\n",
        "        #lbls = []\n",
        "        labels = []\n",
        "        #imgs = []\n",
        "        images = []\n",
        "        pixels = []\n",
        "        ct = 0\n",
        "        for line in training_file:\n",
        "            ct += 1\n",
        "            if ct == 1:\n",
        "                continue\n",
        "            pixel_nums = line.split(',')\n",
        "            #for i in pixel_nums: pixels.append(float(i))\n",
        "            np_img = np.asarray(pixel_nums[1:], dtype = 'float')\n",
        "            img_rows = np.array_split(np_img, 28)\n",
        "            #lbls.append(pixels[0])\n",
        "            #imgs.append(img_rows)\n",
        "            labels.append(float(pixel_nums[0]))\n",
        "            images.append(img_rows)\n",
        "        #labels = np.asarray(lbls)\n",
        "        #images = np.asarray(imgs)\n",
        "        print(max(labels))\n",
        "      # Your code ends here\n",
        "    return images, labels\n",
        "\n",
        "path_sign_mnist_train = f\"{getcwd()}/../tmp2/sign_mnist_train.csv\"\n",
        "path_sign_mnist_test = f\"{getcwd()}/../tmp2/sign_mnist_test.csv\"\n",
        "#training_images, training_labels = get_data(path_sign_mnist_train)\n",
        "#testing_images, testing_labels = get_data(path_sign_mnist_test)\n",
        "\n",
        "tr_img_list, tr_lb_list = get_data(path_sign_mnist_train)\n",
        "t_img_list, t_lb_list = get_data(path_sign_mnist_test)\n",
        "training_images = np.asarray(tr_img_list)\n",
        "training_labels = np.asarray(tr_lb_list)\n",
        "testing_images = np.asarray(t_img_list)\n",
        "testing_labels = np.asarray(t_lb_list)\n",
        "\n",
        "# Keep these\n",
        "print(training_images.shape)\n",
        "print(training_labels.shape)\n",
        "print(testing_images.shape)\n",
        "print(testing_labels.shape)\n",
        "\n",
        "print(training_images)\n",
        "print(training_labels)\n",
        "print(testing_images)\n",
        "print(testing_labels)\n",
        "\n",
        "# Their output should be:\n",
        "# (27455, 28, 28)\n",
        "# (27455,)\n",
        "# (7172, 28, 28)\n",
        "# (7172,)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-68e0e5f1c21b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#testing_images, testing_labels = get_data(path_sign_mnist_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mtr_img_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_lb_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_sign_mnist_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mt_img_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_lb_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_sign_mnist_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mtraining_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_img_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-68e0e5f1c21b>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# You are reading in strings, but need the values to be floats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# Check out np.array().astype for a conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0;31m# Your code starts here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#lbls = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/../tmp2/sign_mnist_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FhszlCO8c3n"
      },
      "source": [
        "# In this section you will have to add another dimension to the data\n",
        "# So, for example, if your array is (10000, 28, 28)\n",
        "# You will need to make it (10000, 28, 28, 1)\n",
        "# Hint: np.expand_dims\n",
        "\n",
        "training_images = np.expand_dims(training_images, axis = 3)\n",
        "testing_images = np.expand_dims(testing_images, axis = 3)\n",
        "\n",
        "# Create an ImageDataGenerator and do Image Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    # Your Code Here\n",
        "    rescale = 1/255,\n",
        "    horizontal_flip = True,\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    fill_mode = 'nearest'\n",
        "    )\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    # Your Code Here\n",
        "    rescale = 1/255\n",
        "    )\n",
        "    \n",
        "train_datagen.fit(training_images)\n",
        "validation_datagen.fit(testing_images)\n",
        "    \n",
        "# Keep These\n",
        "print(training_images.shape)\n",
        "print(testing_images.shape)\n",
        "    \n",
        "# Their output should be:\n",
        "# (27455, 28, 28, 1)\n",
        "# (7172, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9rt5tYF8fbm"
      },
      "source": [
        "# Define the model\n",
        "# Use no more than 2 Conv2D and 2 MaxPooling2D\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Your Code Here\n",
        "    keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D(2, 2),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
        "    keras.layers.MaxPooling2D(2, 2),\n",
        "    keras.layers.Flatten(),\n",
        "    #keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(512, activation = 'relu'),\n",
        "    keras.layers.Dense(26, activation = 'softmax')\n",
        "    ])\n",
        "\n",
        "# Compile Model. \n",
        "model.compile(# Your Code Here\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                optimizers = 'RMSprop',\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit_generator(# Your Code Here (set 'epochs' = 2)\n",
        "                                train_datagen.flow(training_images, training_labels, batch_size = 5),\n",
        "                                epochs = 2,\n",
        "                                steps_per_epoch = len(training_images)/5,\n",
        "                                validation_data = validation_datagen.flow(testing_images, testing_labels, batch_size = 5),\n",
        "                                validation_steps = len(testing_images)/5,\n",
        "                                verbose = 2)\n",
        "\n",
        "model.evaluate(testing_images, testing_labels, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA7-ABeU8hNv"
      },
      "source": [
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq4ou27j8jOJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}